{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa15ffee-dc86-4ad3-a7c9-5d2cd6415085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset and computing physics-derived features...\n",
      "\n",
      "Dataset - sample initial Mach & altitude (first rows):\n",
      "   init_Mach  init_altitude_m  init_velocity_m_s\n",
      "0   6.123056     55331.860305        1806.743155\n",
      "1   9.346442     53898.460533        2757.874443\n",
      "2  10.881701     56534.814283        3210.886838\n",
      "3   7.547179     72989.961414        2226.962193\n",
      "4   6.932314     35548.825560        2045.532755\n",
      "\n",
      "Training classifier...\n",
      "CV ROC-AUC: mean=0.977 std=0.004\n",
      "\n",
      "Test eval:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.912     0.894     0.902       911\n",
      "           1      0.896     0.913     0.904       911\n",
      "\n",
      "    accuracy                          0.903      1822\n",
      "   macro avg      0.904     0.903     0.903      1822\n",
      "weighted avg      0.904     0.903     0.903      1822\n",
      "\n",
      "Confusion matrix:\n",
      " [[814  97]\n",
      " [ 79 832]]\n",
      "ROC-AUC (test): 0.973\n",
      "\n",
      "Feature importance:\n",
      "                 feature  importance\n",
      "8              A_ref_m2    0.274479\n",
      "3     Tw_over_Tinf_init    0.126116\n",
      "6            x_sensor_m    0.125445\n",
      "7               mass_kg    0.096998\n",
      "14     momentum_theta_m    0.048775\n",
      "13           delta_99_m    0.047581\n",
      "15             Re_theta    0.041857\n",
      "11                 Re_x    0.041735\n",
      "4   cone_half_angle_deg    0.034547\n",
      "10             Re_per_m    0.034240\n",
      "1       init_altitude_m    0.030409\n",
      "12              Knudsen    0.023099\n",
      "5         nose_radius_m    0.020246\n",
      "9           roughness_m    0.020217\n",
      "0             init_Mach    0.017218\n",
      "2     init_velocity_m_s    0.017035\n",
      "\n",
      "Chosen randomized initial condition (after 2 attempt(s)):\n",
      "  Mach0 = 6.034293321807626, Alt0 = 81793.5 m, U0 = 1780.55 m/s, a0 = 295.07 m/s\n",
      "  A_ref = 81.5381 m^2, mass = 462.6 kg, nose_radius = 0.0284 m\n",
      "  x_sensor = 0.023 m, cone_half = 6.929 deg, roughness = 1.528e-04\n",
      "  initial predicted transition probability = 0.065 (pred=0)\n",
      "\n",
      "Simulation initial (reported): Mach0=6.034293321807626, Alt0=81793.5 m, U0=1780.55 m/s\n",
      "\n",
      "No transition detected during simulation (within runtime/criteria).\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "hypersonic_transition_with_dataset.py\n",
    "\n",
    "Modified prototype that reads a provided dataset (CSV) instead of building a synthetic\n",
    "training set. The script now:\n",
    " - reads /mnt/data/Mach_4.5_to_12_dataset.csv\n",
    " - builds a classifier to predict `transition_detected` from initial / instantaneous\n",
    "   flow + vehicle parameters present in the CSV\n",
    " - runs a trajectory and uses the trained classifier at each timestep (computing the\n",
    "   same instantaneous features) to detect transition\n",
    "\n",
    "Notes:\n",
    " - This is still a demo/prototype. Treat results cautiously until surrogates are\n",
    "   replaced with physically-validated models.\n",
    " - The dataset columns used for inputs are documented below and in the code.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -------------------------\n",
    "# Constants / vehicle props (defaults; per-sample values can override)\n",
    "# -------------------------\n",
    "R = 287.058            # J/(kg·K)\n",
    "gamma = 1.4\n",
    "mu0 = 1.716e-5         # kg/(m·s) at T0\n",
    "T0_ref = 273.15        # K reference for mu0\n",
    "S = 110.4              # Sutherland's constant (K)\n",
    "\n",
    "# Default vehicle properties (will be overwritten by dataset values where available)\n",
    "cone_half_angle = 10.0         # degrees (for reference)\n",
    "nose_radius = 0.01             # m\n",
    "x_sensor = 1.0                 # m along surface from stagnation (demo)\n",
    "T_w = 300.0                    # K wall temperature (assumed)\n",
    "m_vehicle = 500.0              # kg (must set realistically)\n",
    "A_ref = np.pi * nose_radius**2 # reference frontal area (m^2) - change if needed\n",
    "roughness = 1e-6               # m\n",
    "\n",
    "# -------------------------\n",
    "# Atmosphere (piecewise ISA up to ~100 km)\n",
    "# -------------------------\n",
    "def atmosphere(h):\n",
    "    if h < 11000:\n",
    "        T = 288.15 - 0.0065 * h\n",
    "        p = 101325.0 * (T / 288.15) ** 5.255877\n",
    "    elif h < 20000:\n",
    "        T = 216.65\n",
    "        p11 = 101325.0 * (216.65 / 288.15) ** 5.255877\n",
    "        p = p11 * np.exp(- (h - 11000) / 6341.97)\n",
    "    else:\n",
    "        T = 216.65\n",
    "        rho0 = 0.08803\n",
    "        scale_h = 7000.0\n",
    "        rho = rho0 * np.exp(-(h - 20000)/scale_h)\n",
    "        p = rho * R * T\n",
    "        return T, p, rho\n",
    "    rho = p / (R * T)\n",
    "    return T, p, rho\n",
    "\n",
    "# -------------------------\n",
    "# Sutherland viscosity\n",
    "# -------------------------\n",
    "def viscosity_sutherland(T):\n",
    "    return mu0 * (T / T0_ref)**1.5 * (T0_ref + S) / (T + S)\n",
    "\n",
    "# -------------------------\n",
    "# Simple aerodynamic coeffs (kept as placeholders)\n",
    "# -------------------------\n",
    "def drag_coeff(M, cone_half_angle_deg):\n",
    "    base = 0.2 + 0.005 * cone_half_angle_deg\n",
    "    if M < 0.8:\n",
    "        return base + 0.3\n",
    "    elif M < 2.0:\n",
    "        return base + 0.6\n",
    "    elif M < 5.0:\n",
    "        return base + 0.9\n",
    "    else:\n",
    "        return base + 1.2\n",
    "\n",
    "def lift_coeff(M, cone_half_angle_deg):\n",
    "    return 0.01 * np.tan(np.radians(cone_half_angle_deg))\n",
    "\n",
    "# -------------------------\n",
    "# Trajectory model (fixed physics)\n",
    "# -------------------------\n",
    "def trajectory_model(state, t, params):\n",
    "    h, U, theta = state\n",
    "    m = params['m']\n",
    "    T_inf, p_inf, rho_inf = atmosphere(h)\n",
    "    if T_inf <= 0 or rho_inf <= 0:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "    a = np.sqrt(gamma * R * T_inf)\n",
    "    M = max(U / a, 1e-6)\n",
    "\n",
    "    C_D = drag_coeff(M, params['cone_half_angle'])\n",
    "    C_L = lift_coeff(M, params['cone_half_angle'])\n",
    "\n",
    "    D = 0.5 * rho_inf * U**2 * C_D * params['A_ref']\n",
    "    L = 0.5 * rho_inf * U**2 * C_L * params['A_ref']\n",
    "\n",
    "    g0 = 9.80665\n",
    "    R_earth = 6371e3\n",
    "    g = g0 * (R_earth / (R_earth + h))**2\n",
    "\n",
    "    dUdt = -D / m - g * np.sin(theta)\n",
    "    dthetadt = 0.0\n",
    "    if U > 1e-3:\n",
    "        dthetadt = (L / m) / U - (g * np.cos(theta)) / U\n",
    "    dhdt = U * np.sin(theta)\n",
    "    return [dhdt, dUdt, dthetadt]\n",
    "\n",
    "# -------------------------\n",
    "# Dataset loader\n",
    "# -------------------------\n",
    "def load_dataset(csv_path):\n",
    "    \"\"\"Read CSV and build X, y for classifier training.\n",
    "\n",
    "    The CSV provided (example: /mnt/data/Mach_4.5_to_12_dataset.csv) contains many\n",
    "    columns. For training we construct a feature vector from the \"initial\" conditions\n",
    "    and vehicle geometry and operating parameters that are present for all samples.\n",
    "\n",
    "    Features used (per-row):\n",
    "      - init_Mach\n",
    "      - init_altitude_m\n",
    "      - init_velocity_m_s\n",
    "      - Tw_over_Tinf_init\n",
    "      - cone_half_angle_deg\n",
    "      - nose_radius_m\n",
    "      - x_sensor_m\n",
    "      - mass_kg\n",
    "      - A_ref_m2\n",
    "      - roughness_m\n",
    "\n",
    "    Label: transition_detected (boolean -> 1/0)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # ensure expected columns exist\n",
    "    expected = ['init_Mach', 'init_altitude_m', 'init_velocity_m_s', 'Tw_over_Tinf_init',\n",
    "                'cone_half_angle_deg', 'nose_radius_m', 'x_sensor_m', 'mass_kg', 'A_ref_m2', 'roughness_m',\n",
    "                'transition_detected']\n",
    "    missing = [c for c in expected if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing expected columns in dataset: {missing}\")\n",
    "\n",
    "    # select features and label\n",
    "    X = df[expected[:-1]].copy()\n",
    "    y = df['transition_detected'].astype(bool).astype(int).values\n",
    "\n",
    "    # handle missing feature values with simple imputation (median)\n",
    "    imp = SimpleImputer(strategy='median')\n",
    "    X_imputed = imp.fit_transform(X)\n",
    "\n",
    "    # standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "    # return scaler & imputer so we can use them at inference time\n",
    "    return X_scaled, y, scaler, imp\n",
    "\n",
    "# -------------------------\n",
    "# Train classifier (Random Forest)\n",
    "# -------------------------\n",
    "def train_classifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    clf = RandomForestClassifier(n_estimators=200, random_state=0, class_weight='balanced')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Classifier evaluation on dataset test set:\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    return clf\n",
    "\n",
    "# -------------------------\n",
    "# Utility to build feature vector at runtime for classifier (match training order)\n",
    "# -------------------------\n",
    "def build_feature_vector_for_state(h, U, T_inf, rho_inf, params):\n",
    "    # instantaneous Mach\n",
    "    a = np.sqrt(gamma * R * T_inf)\n",
    "    M_e = max(U / a, 1e-6)\n",
    "    # Tw/Tinf estimate using provided wall temp (params may contain T_w)\n",
    "    Tw = params.get('T_w', T_w)\n",
    "    Tw_over_Tinf = Tw / max(T_inf, 1.0)\n",
    "\n",
    "    feat = [\n",
    "        M_e,\n",
    "        h,\n",
    "        U,\n",
    "        Tw_over_Tinf,\n",
    "        params.get('cone_half_angle', cone_half_angle),\n",
    "        params.get('nose_radius', nose_radius),\n",
    "        params.get('x_sensor', x_sensor),\n",
    "        params.get('m', m_vehicle),\n",
    "        params.get('A_ref', A_ref),\n",
    "        params.get('roughness', roughness)\n",
    "    ]\n",
    "    return np.array(feat, dtype=float).reshape(1, -1)\n",
    "\n",
    "# -------------------------\n",
    "# Main simulation & detection (using classifier trained on dataset)\n",
    "# -------------------------\n",
    "def run_simulation_and_detect_transition(clf, scaler, imputer):\n",
    "    # initial state (example) - kept same as original demo\n",
    "    state0 = [100000.0, 7000.0, -20.0 * np.pi / 180.0]\n",
    "    t = np.linspace(0.0, 1000.0, 2000)  # s\n",
    "    params = {'m': m_vehicle, 'cone_half_angle': cone_half_angle, 'A_ref': A_ref,\n",
    "              'x_sensor': x_sensor, 'T_w': T_w, 'nose_radius': nose_radius, 'roughness': roughness}\n",
    "    states = odeint(trajectory_model, state0, t, args=(params,), atol=1e-6, rtol=1e-6)\n",
    "\n",
    "    h_vec = states[:, 0]\n",
    "    U_vec = states[:, 1]\n",
    "    theta_vec = states[:, 2]\n",
    "\n",
    "    h_trans = None\n",
    "    M_trans = None\n",
    "    transition_index = None\n",
    "\n",
    "    for i, h in enumerate(h_vec):\n",
    "        U = U_vec[i]\n",
    "        if U <= 50 or h <= 0:\n",
    "            break\n",
    "        T_inf, p_inf, rho_inf = atmosphere(h)\n",
    "        if rho_inf <= 0 or T_inf <= 0:\n",
    "            continue\n",
    "        feat = build_feature_vector_for_state(h, U, T_inf, rho_inf, params)\n",
    "        # apply imputer & scaler used in training\n",
    "        feat_imp = imputer.transform(feat)\n",
    "        feat_scaled = scaler.transform(feat_imp)\n",
    "        state_pred = clf.predict(feat_scaled)[0]\n",
    "        if state_pred == 1:\n",
    "            h_trans = h\n",
    "            M_trans = U / np.sqrt(gamma * R * T_inf)\n",
    "            transition_index = i\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'h_trans': h_trans,\n",
    "        'M_trans': M_trans,\n",
    "        'states': states,\n",
    "        't': t,\n",
    "        'transition_index': transition_index\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# Run everything\n",
    "# -------------------------\n",
    "def main(csv_path='F:\\RNN based Object detection and Anomaly Classification surveillance System\\Hypersonic Boundary Layer Transition Prediction\\generated_dataset_M4.5-12_cone_trajectory_10000.csv'):\n",
    "    print(\"Loading dataset from:\", csv_path)\n",
    "    X, y, scaler, imputer = load_dataset(csv_path)\n",
    "    print(\"Dataset shape (features, labels):\", X.shape, y.shape)\n",
    "    print(\"Training classifier on provided dataset...\")\n",
    "    clf = train_classifier(X, y)\n",
    "    print(\"Running trajectory simulation and detecting transition (dataset-driven)...\")\n",
    "    results = run_simulation_and_detect_transition(clf, scaler, imputer)\n",
    "\n",
    "    if results['h_trans'] is not None:\n",
    "        print(f\"Predicted transition altitude: {results['h_trans']:.1f} m\")\n",
    "        print(f\"Predicted transition Mach number: {results['M_trans']:.3f}\")\n",
    "    else:\n",
    "        print(\"No transition detected during the simulated trajectory (with current classifier).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6431eee-a2b4-4472-bf4e-e242bbd0cad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
